{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "\n",
    "import time\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. DATA PREP\n",
    "\n",
    "* **Raw Data**\n",
    "    * Fake translation data for sanity check.\n",
    "    * The first sentence is A -> H, the second one letter off, i.e. B -> I.\n",
    "    \n",
    "* **Desired Format for Model**\n",
    "    * An indexer that maps between words and word indices.\n",
    "    * The data: a list of lists, where each sublist is a pair of index-coded sentences.\n",
    "    * The lengths: for each sentence pair, we have their lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexer:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {} # str -> int\n",
    "        self.index2word = {}\n",
    "        self.word2count = {} # str -> int\n",
    "        self.nWords = 0  # Count SOS and EOS\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.nWords\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.nWords] = word\n",
    "            self.nWords += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1 \n",
    "            \n",
    "    def get_index(self, word):\n",
    "        return self.word2index[word] if word in self.word2index else -1\n",
    "    \n",
    "    def get_word(self, index):\n",
    "        return self.index2word[index] if index<self.nWords else \"\"\n",
    "    \n",
    "    def get_sentence_index(self, sentence):\n",
    "        return [self.get_index(word) for word in sentence]\n",
    "    \n",
    "    def get_sentence_word(self, indexSentence):\n",
    "        return [self.get_word(index) for index in indexSentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = [chr(i) for i in range(65,74)] # 'A' -> 'I'\n",
    "FROM_LEN, TO_LEN = 3, 8\n",
    "MAX_LENGTH = TO_LEN + 2\n",
    "SOS, EOS = 'SOS', 'EOS'\n",
    "INDEXER = Indexer('LetterTranslator')\n",
    "DATA_SIZE = 3000\n",
    "\n",
    "def translate_word(word):\n",
    "    return VOCAB[VOCAB.index(word)+1]\n",
    "\n",
    "def translate_sent(sent):\n",
    "    return [translate_word(word) for word in sent]\n",
    "\n",
    "def generate_pair():\n",
    "    randInput = list(np.random.choice(VOCAB[:-1], size=random.randint(FROM_LEN,TO_LEN)))\n",
    "    randTarget = translate_sent(randInput)\n",
    "    randInputLen, randTargetLen = len(randInput), len(randTarget)\n",
    "    return [str('SOS')]+randInput+[str('EOS')], [str('SOS')]+randTarget+[str('EOS')], \\\n",
    "           randInputLen+2, randTargetLen+2\n",
    "        # str(): default is utf-8\n",
    "\n",
    "def generate_data():\n",
    "    pairs, lengths = [], []\n",
    "    for _ in range(DATA_SIZE):\n",
    "        randInput,randTarget,randInputLen,randTargetLen = generate_pair()\n",
    "        INDEXER.add_sentence(randInput)\n",
    "        INDEXER.add_sentence(randTarget)\n",
    "        pairs.append([INDEXER.get_sentence_index(randInput),\n",
    "                      INDEXER.get_sentence_index(randTarget)])\n",
    "        lengths.append([randInputLen,randTargetLen])\n",
    "    return pairs, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs, lengths = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(sentence):\n",
    "    \"\"\"Convert a sentence into a <max-time,batch-size> shaped torch tensor.\n",
    "    Args\n",
    "        sentence: a list of word indices.\n",
    "    Returns\n",
    "        the same sentence in torch.Tensor.\n",
    "    \"\"\"\n",
    "    return torch.tensor(sentence, dtype=torch.long, device=device).view(-1,1) \n",
    "        # <mt,> -> <mt,bc=1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"A simple unidirectional GRU encoder.\"\"\"\n",
    "    \n",
    "    def __init__(self, inputSize, hiddenSize):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            inputSize: (combined) vocabulary size of the translated languages.\n",
    "            hiddenSize: hidden vector size, used for both embeddings and GRU here.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.embedding = nn.Embedding(inputSize, hiddenSize)\n",
    "        self.gru = nn.GRU(hiddenSize, hiddenSize)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"The function called by Encoder().\n",
    "        Args\n",
    "            input: a word index.\n",
    "            hidden: an initial word index (i.e. SOS).\n",
    "        Returns\n",
    "            output: outputs of GRU (max-time,batch-size,hidden).\n",
    "            hidden: the last hidden state of the GRU.\n",
    "        \"\"\"\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "            # format into <max-time,batch-size,hidden>\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "            # output: <max-time,batch-size,hidden>\n",
    "            # hidden: <n_layers*n_directions,batch-size,hidden>\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \"\"\"Initializer of the first input to a GRU.\n",
    "        Returns\n",
    "            A (max-time=1,batch-size=1,hidden) shaped zero tensor. # TODO: revise this.\n",
    "        \"\"\"\n",
    "        return torch.zeros(1, 1, self.hiddenSize, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A simple unidirectional GRU decoder.\"\"\"\n",
    "    \n",
    "    def __init__(self, inputSize, hiddenSize):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            inputSize: (combined) vocabulary size of the translated languages.\n",
    "            hiddenSize: hidden vector size, used for both embeddings and GRU here.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.embedding = nn.Embedding(inputSize, hiddenSize)\n",
    "        self.gru = nn.GRU(hiddenSize, hiddenSize)\n",
    "        self.fc = nn.Linear(hiddenSize, inputSize) # inputSize=outputSize=vocab\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # it will be applied on <bc,outputSize> tensor.\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.fc(output[0])\n",
    "        output = F.relu(output) # only .nn.functional.relu works, .nn.ReLU doesn't\n",
    "        output = self.softmax(output)\n",
    "            # input size: torch.Size([1]) <- 1 word's index (1 time step).\n",
    "            # to gru: torch.Size([1, 1, 5]) <max-time,batch-size,hidden>\n",
    "            # after gru: torch.Size([1, 1, 5]) <max-time,batch-size,hidden>\n",
    "            # after fc: torch.Size([1, 7119]) <batch-size,vocab-size>\n",
    "            # after relu: torch.Size([1, 7119]) <batch-size,vocab-size>\n",
    "            # after softmax: torch.Size([1, 7119]) <batch-size,vocab-size>\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER STEP\n",
      "\n",
      "\n",
      "Read 1 source sentence (in code):\n",
      "[0, 1, 2, 3, 4, 3, 5, 6] \n",
      "\n",
      "Convert to torch.tensor:\n",
      "tensor([[ 0],\n",
      "        [ 1],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 3],\n",
      "        [ 5],\n",
      "        [ 6]]) torch.Size([8, 1]) \n",
      "\n",
      "Run through encoder (10 max-time, hidden = 5):\n",
      "shape of encoder outputs: (output, hidden)\n",
      "output = torch.Size([1, 1, 5]) | hidden = torch.Size([1, 1, 5]) \n",
      "\n",
      "Final content in encoder output container:\n",
      "tensor([[-0.0720, -0.3249,  0.0433,  0.4857, -0.2185],\n",
      "        [-0.4414, -0.1157,  0.3488,  0.2779, -0.0563],\n",
      "        [-0.5602,  0.0517,  0.5414,  0.1268, -0.0166],\n",
      "        [ 0.1437,  0.2044,  0.5803,  0.4327,  0.3196],\n",
      "        [-0.1980,  0.1108,  0.5918,  0.1437,  0.2102],\n",
      "        [ 0.2579,  0.2426,  0.5940,  0.4475,  0.4277],\n",
      "        [ 0.0358,  0.0343,  0.4197,  0.2064, -0.3539],\n",
      "        [-0.0381, -0.3561,  0.3072,  0.5485, -0.2567],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([10, 5])\n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "DECODER STEP\n",
      "\n",
      "\n",
      "Read 1 target sentence (in code):\n",
      "[0, 3, 4, 7, 8, 7, 9, 6] \n",
      "\n",
      "Convert to torch.tensor:\n",
      "tensor([[ 0],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [ 6]]) torch.Size([8, 1]) \n",
      "\n",
      "Set up loss criterion:\n",
      "NLLLoss() \n",
      "\n",
      "Run through decoder (10 max-time, hidden = 5):\n",
      "shape of decoder outputs: (output, hidden)\n",
      "output = torch.Size([1, 11]) | hidden = torch.Size([1, 1, 5]) \n",
      "\n",
      "Loss trace:\n",
      "loss = tensor(2.2002)\n",
      "loss = tensor(4.7302)\n",
      "loss = tensor(7.0901)\n",
      "loss = tensor(9.6506)\n",
      "loss = tensor(12.1000)\n",
      "loss = tensor(14.6583)\n",
      "loss = tensor(17.1567)\n",
      "loss = tensor(19.7158)\n"
     ]
    }
   ],
   "source": [
    "# Demo how the Encoder and Decoder classes work\n",
    "\n",
    "print('ENCODER STEP\\n\\n')\n",
    "print('Read 1 source sentence (in code):')\n",
    "a1 = pairs[0][0]\n",
    "print(a1, '\\n')\n",
    "a1 = to_tensor(a1)\n",
    "print('Convert to torch.tensor:')\n",
    "print(a1, a1.shape, '\\n')\n",
    "print('Run through encoder (10 max-time, hidden = 5):')\n",
    "e = Encoder(INDEXER.nWords, hiddenSize=5)\n",
    "eh = e.init_hidden()\n",
    "eos = torch.zeros(10,5,device=device) # <mt,h>\n",
    "for i in range(len(a1)):\n",
    "    eo,eh = e(a1[i], eh) # outshape = <mt,bc,h> [1,1,5] \n",
    "    if i==0:\n",
    "        print('shape of encoder outputs: (output, hidden)')\n",
    "        print('output =', eo.shape, '| hidden =', eh.shape, '\\n')\n",
    "    eos[i] = eo[0][0] # a <5,> vector.\n",
    "print('Final content in encoder output container:')\n",
    "print(eos)\n",
    "print(eos.shape)\n",
    "print('\\n====================\\n\\n')\n",
    "print('DECODER STEP\\n\\n')\n",
    "print('Read 1 target sentence (in code):')\n",
    "a2 = pairs[0][1]\n",
    "print(a2, '\\n')\n",
    "a2 = to_tensor(a2)\n",
    "print('Convert to torch.tensor:')\n",
    "print(a2, a2.shape, '\\n')\n",
    "print('Set up loss criterion:')\n",
    "l = 0 \n",
    "crit = nn.NLLLoss()\n",
    "print(crit, '\\n')\n",
    "print('Run through decoder (10 max-time, hidden = 5):')\n",
    "d = Decoder(INDEXER.nWords, hiddenSize=5)\n",
    "di = torch.tensor([[INDEXER.get_index(SOS)]],device=device) # SOS token as the first\n",
    "dh = eh # init decoder hidden as encoder last hidden\n",
    "for i in range(len(a2)):\n",
    "    do,dh = d(di, dh)\n",
    "    if i==0:\n",
    "        print('shape of decoder outputs: (output, hidden)')\n",
    "        print('output =', do.shape, '| hidden =', dh.shape, '\\n')\n",
    "        print('Loss trace:')\n",
    "    tv,ti = do.topk(1)\n",
    "#     di = ti.squeeze().detach()\n",
    "    di = ti\n",
    "#     print(ti); assert 1==0\n",
    "        # rid of all 1-dims, then detach from graph (no grad)\n",
    "        # tv, ti shapes: [1,1]\n",
    "        # .squeeze(): Returns a tensor with all the dimensions of input of size 1 removed.\n",
    "        # .detach(): Returns a new Tensor, detached from the current graph.\n",
    "        #            The result will never require gradient.\n",
    "    l += crit(do,a2[i]) # do: <1,outputSize> (softmax); a2[i]: <1,>\n",
    "    print('loss =', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C. TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pairs, lengths, encoder, decoder, encoderOptim, decoderOptim, criterion,\n",
    "          nEpochs=5, printEvery=100):\n",
    "    totalLosses = []\n",
    "    start = time.time()\n",
    "    for e in range(nEpochs):\n",
    "        currLosses = []\n",
    "        for i in range(len(pairs)):\n",
    "            encoderOptim.zero_grad()\n",
    "            decoderOptim.zero_grad()\n",
    "            currSource, currTarget = pairs[i]\n",
    "            currSource, currTarget = to_tensor(currSource), to_tensor(currTarget)\n",
    "            currSourceLength, currTargetLength = lengths[i]\n",
    "            encoderOptim.zero_grad()\n",
    "            decoderOptim.zero_grad()\n",
    "            loss = 0\n",
    "            encoderOutputs = torch.zeros(MAX_LENGTH, encoder.hiddenSize, device=device) # for attention later\n",
    "            encoderHidden = encoder.init_hidden()\n",
    "            for ei in range(currSourceLength):\n",
    "                encoderOutput,encoderHidden = encoder(currSource[ei],encoderHidden)\n",
    "                encoderOutputs[ei] = encoderOutput[0][0] # <mt=bc=1,h>\n",
    "            decoderInput = torch.tensor([[INDEXER.get_index(SOS)]], device=device)\n",
    "            decoderHidden = encoderHidden\n",
    "            for di in range(currTargetLength):\n",
    "                decoderOutput,decoderHidden = decoder(decoderInput,decoderHidden)\n",
    "                topValue,topIndex = decoderOutput.topk(1)\n",
    "                decoderInput = topIndex\n",
    "#                 decoderInput = topIndex.squeeze().detach()\n",
    "                loss += criterion(decoderOutput,currTarget[di]) \n",
    "                    # decoderOutput: <batch-size,vocab-size>, a dist'n over vocab.\n",
    "                    # currTarget[di]: <batch-size>\n",
    "                if decoderInput.item() == INDEXER.get_index(EOS):\n",
    "                    break # hitting end of sentence\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(),5.0)\n",
    "            torch.nn.utils.clip_grad_norm_(decoder.parameters(),5.0)\n",
    "            encoderOptim.step()\n",
    "            decoderOptim.step()\n",
    "            currAverageLoss = loss.item()/currTargetLength\n",
    "            if i!=0 and i%printEvery==0:\n",
    "                print('Loss at epoch %d step %d = %.4f (time=%.4f)' % (e+1,i,currAverageLoss,\n",
    "                                                                       time.time()-start))\n",
    "                start = time.time()\n",
    "            currLosses.append(currAverageLoss)\n",
    "        totalLosses.append(np.mean(currLosses))\n",
    "    return np.mean(totalLosses), encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1 step 100 = 2.2591 (time=0.8450)\n",
      "Loss at epoch 1 step 200 = 2.3338 (time=1.1297)\n",
      "Loss at epoch 1 step 300 = 2.0589 (time=1.2362)\n",
      "Loss at epoch 1 step 400 = 1.5477 (time=1.2525)\n",
      "Loss at epoch 1 step 500 = 1.5423 (time=1.2260)\n",
      "Loss at epoch 1 step 600 = 2.2691 (time=1.1925)\n",
      "Loss at epoch 1 step 700 = 1.6829 (time=1.1818)\n",
      "Loss at epoch 1 step 800 = 1.2130 (time=1.1494)\n",
      "Loss at epoch 1 step 900 = 1.3797 (time=1.1999)\n",
      "Loss at epoch 1 step 1000 = 1.8641 (time=1.3682)\n",
      "Loss at epoch 1 step 1100 = 1.4812 (time=1.1423)\n",
      "Loss at epoch 1 step 1200 = 1.5155 (time=1.1544)\n",
      "Loss at epoch 1 step 1300 = 1.0976 (time=1.1058)\n",
      "Loss at epoch 1 step 1400 = 2.1136 (time=1.1800)\n",
      "Loss at epoch 1 step 1500 = 2.1184 (time=1.1952)\n",
      "Loss at epoch 1 step 1600 = 1.4907 (time=1.1655)\n",
      "Loss at epoch 1 step 1700 = 1.5913 (time=1.1756)\n",
      "Loss at epoch 1 step 1800 = 0.9895 (time=1.1751)\n",
      "Loss at epoch 1 step 1900 = 1.2311 (time=1.2401)\n",
      "Loss at epoch 1 step 2000 = 1.8789 (time=1.2590)\n",
      "Loss at epoch 1 step 2100 = 1.8550 (time=1.2548)\n",
      "Loss at epoch 1 step 2200 = 1.9828 (time=1.1817)\n",
      "Loss at epoch 1 step 2300 = 1.9009 (time=1.2299)\n",
      "Loss at epoch 1 step 2400 = 1.4847 (time=1.2449)\n",
      "Loss at epoch 1 step 2500 = 1.8960 (time=1.3386)\n",
      "Loss at epoch 1 step 2600 = 1.3266 (time=1.2601)\n",
      "Loss at epoch 1 step 2700 = 1.6222 (time=1.2001)\n",
      "Loss at epoch 1 step 2800 = 2.0012 (time=1.2196)\n",
      "Loss at epoch 1 step 2900 = 1.9216 (time=1.1451)\n",
      "Loss at epoch 2 step 100 = 1.8387 (time=2.4442)\n",
      "Loss at epoch 2 step 200 = 1.9494 (time=1.3592)\n",
      "Loss at epoch 2 step 300 = 1.5089 (time=1.2921)\n",
      "Loss at epoch 2 step 400 = 1.9109 (time=1.2832)\n",
      "Loss at epoch 2 step 500 = 1.2718 (time=1.2484)\n",
      "Loss at epoch 2 step 600 = 1.8207 (time=1.2088)\n",
      "Loss at epoch 2 step 700 = 1.1154 (time=1.2174)\n",
      "Loss at epoch 2 step 800 = 0.9487 (time=1.3108)\n",
      "Loss at epoch 2 step 900 = 1.1509 (time=1.3202)\n",
      "Loss at epoch 2 step 1000 = 1.9860 (time=1.3885)\n",
      "Loss at epoch 2 step 1100 = 1.6100 (time=1.3115)\n",
      "Loss at epoch 2 step 1200 = 1.7619 (time=1.2303)\n",
      "Loss at epoch 2 step 1300 = 1.5342 (time=1.2352)\n",
      "Loss at epoch 2 step 1400 = 1.7868 (time=1.2419)\n",
      "Loss at epoch 2 step 1500 = 2.0061 (time=1.2270)\n",
      "Loss at epoch 2 step 1600 = 2.0124 (time=1.2137)\n",
      "Loss at epoch 2 step 1700 = 1.7975 (time=1.2050)\n",
      "Loss at epoch 2 step 1800 = 1.4614 (time=1.2826)\n",
      "Loss at epoch 2 step 1900 = 1.4401 (time=1.2318)\n",
      "Loss at epoch 2 step 2000 = 1.5321 (time=1.2733)\n",
      "Loss at epoch 2 step 2100 = 1.6733 (time=1.2722)\n",
      "Loss at epoch 2 step 2200 = 1.7746 (time=1.1910)\n",
      "Loss at epoch 2 step 2300 = 1.9466 (time=1.2082)\n",
      "Loss at epoch 2 step 2400 = 1.1593 (time=1.2565)\n",
      "Loss at epoch 2 step 2500 = 1.8058 (time=1.2197)\n",
      "Loss at epoch 2 step 2600 = 1.8142 (time=1.1903)\n",
      "Loss at epoch 2 step 2700 = 1.5796 (time=1.2307)\n",
      "Loss at epoch 2 step 2800 = 1.9572 (time=1.2547)\n",
      "Loss at epoch 2 step 2900 = 1.7929 (time=1.2519)\n",
      "Loss at epoch 3 step 100 = 1.8475 (time=2.6720)\n",
      "Loss at epoch 3 step 200 = 1.8036 (time=1.3052)\n",
      "Loss at epoch 3 step 300 = 1.7326 (time=1.2471)\n",
      "Loss at epoch 3 step 400 = 1.3328 (time=1.2349)\n",
      "Loss at epoch 3 step 500 = 1.4558 (time=1.2156)\n",
      "Loss at epoch 3 step 600 = 1.7386 (time=1.2643)\n",
      "Loss at epoch 3 step 700 = 1.7891 (time=1.2139)\n",
      "Loss at epoch 3 step 800 = 1.1485 (time=1.2040)\n",
      "Loss at epoch 3 step 900 = 1.6285 (time=1.2202)\n",
      "Loss at epoch 3 step 1000 = 1.9107 (time=1.2430)\n",
      "Loss at epoch 3 step 1100 = 1.7470 (time=1.2381)\n",
      "Loss at epoch 3 step 1200 = 1.9397 (time=1.2661)\n",
      "Loss at epoch 3 step 1300 = 1.5007 (time=1.2282)\n",
      "Loss at epoch 3 step 1400 = 1.8866 (time=1.2261)\n",
      "Loss at epoch 3 step 1500 = 1.9612 (time=1.2374)\n",
      "Loss at epoch 3 step 1600 = 1.7619 (time=1.2872)\n",
      "Loss at epoch 3 step 1700 = 1.8150 (time=1.2190)\n",
      "Loss at epoch 3 step 1800 = 1.1966 (time=1.2501)\n",
      "Loss at epoch 3 step 1900 = 1.4195 (time=1.2904)\n",
      "Loss at epoch 3 step 2000 = 1.5568 (time=1.3820)\n",
      "Loss at epoch 3 step 2100 = 1.6605 (time=1.3117)\n",
      "Loss at epoch 3 step 2200 = 1.6659 (time=1.2489)\n",
      "Loss at epoch 3 step 2300 = 1.8189 (time=1.2933)\n",
      "Loss at epoch 3 step 2400 = 1.4928 (time=1.2907)\n",
      "Loss at epoch 3 step 2500 = 1.6337 (time=1.2372)\n",
      "Loss at epoch 3 step 2600 = 1.5544 (time=1.2525)\n",
      "Loss at epoch 3 step 2700 = 1.2101 (time=1.2739)\n",
      "Loss at epoch 3 step 2800 = 1.8593 (time=1.2554)\n",
      "Loss at epoch 3 step 2900 = 1.7245 (time=1.2504)\n",
      "Loss at epoch 4 step 100 = 1.6694 (time=2.5035)\n",
      "Loss at epoch 4 step 200 = 1.5807 (time=1.3968)\n",
      "Loss at epoch 4 step 300 = 1.7344 (time=1.2411)\n",
      "Loss at epoch 4 step 400 = 1.2798 (time=1.2622)\n",
      "Loss at epoch 4 step 500 = 1.4291 (time=1.6619)\n",
      "Loss at epoch 4 step 600 = 1.5871 (time=2.1586)\n",
      "Loss at epoch 4 step 700 = 1.4103 (time=1.2134)\n",
      "Loss at epoch 4 step 800 = 1.1102 (time=1.2438)\n",
      "Loss at epoch 4 step 900 = 1.3996 (time=1.2109)\n",
      "Loss at epoch 4 step 1000 = 1.6268 (time=1.3024)\n",
      "Loss at epoch 4 step 1100 = 1.6192 (time=1.2138)\n",
      "Loss at epoch 4 step 1200 = 1.8790 (time=1.2389)\n",
      "Loss at epoch 4 step 1300 = 1.5125 (time=1.2391)\n",
      "Loss at epoch 4 step 1400 = 1.8755 (time=1.2103)\n",
      "Loss at epoch 4 step 1500 = 1.9362 (time=1.2042)\n",
      "Loss at epoch 4 step 1600 = 1.7510 (time=1.1726)\n",
      "Loss at epoch 4 step 1700 = 1.5139 (time=1.2370)\n",
      "Loss at epoch 4 step 1800 = 1.4474 (time=1.2196)\n",
      "Loss at epoch 4 step 1900 = 1.7079 (time=1.2058)\n",
      "Loss at epoch 4 step 2000 = 1.5695 (time=1.2742)\n",
      "Loss at epoch 4 step 2100 = 1.6113 (time=1.2662)\n",
      "Loss at epoch 4 step 2200 = 1.6491 (time=1.2351)\n",
      "Loss at epoch 4 step 2300 = 1.3179 (time=1.2223)\n",
      "Loss at epoch 4 step 2400 = 1.4461 (time=1.2259)\n",
      "Loss at epoch 4 step 2500 = 1.5394 (time=1.2551)\n",
      "Loss at epoch 4 step 2600 = 1.5225 (time=1.2645)\n",
      "Loss at epoch 4 step 2700 = 1.2181 (time=1.2500)\n",
      "Loss at epoch 4 step 2800 = 1.8485 (time=1.2382)\n",
      "Loss at epoch 4 step 2900 = 1.7006 (time=1.2035)\n",
      "Loss at epoch 5 step 100 = 1.4028 (time=2.4634)\n",
      "Loss at epoch 5 step 200 = 1.5191 (time=1.2325)\n",
      "Loss at epoch 5 step 300 = 1.7098 (time=1.2428)\n",
      "Loss at epoch 5 step 400 = 1.2496 (time=1.2194)\n",
      "Loss at epoch 5 step 500 = 1.4040 (time=1.2103)\n",
      "Loss at epoch 5 step 600 = 1.5482 (time=1.2463)\n",
      "Loss at epoch 5 step 700 = 1.6624 (time=1.2534)\n",
      "Loss at epoch 5 step 800 = 1.1033 (time=1.2632)\n",
      "Loss at epoch 5 step 900 = 1.4083 (time=1.2053)\n",
      "Loss at epoch 5 step 1000 = 1.6005 (time=1.2120)\n",
      "Loss at epoch 5 step 1100 = 1.5686 (time=1.2022)\n",
      "Loss at epoch 5 step 1200 = 1.8643 (time=1.2068)\n",
      "Loss at epoch 5 step 1300 = 1.5155 (time=1.1918)\n",
      "Loss at epoch 5 step 1400 = 1.8437 (time=1.1889)\n",
      "Loss at epoch 5 step 1500 = 1.5338 (time=1.2172)\n",
      "Loss at epoch 5 step 1600 = 1.7221 (time=1.2123)\n",
      "Loss at epoch 5 step 1700 = 1.5209 (time=1.2383)\n",
      "Loss at epoch 5 step 1800 = 1.4140 (time=1.2120)\n",
      "Loss at epoch 5 step 1900 = 1.8516 (time=1.2329)\n",
      "Loss at epoch 5 step 2000 = 1.7949 (time=1.2827)\n",
      "Loss at epoch 5 step 2100 = 1.4770 (time=1.2630)\n",
      "Loss at epoch 5 step 2200 = 1.6195 (time=1.2375)\n",
      "Loss at epoch 5 step 2300 = 1.6209 (time=1.2580)\n",
      "Loss at epoch 5 step 2400 = 1.6724 (time=1.2346)\n",
      "Loss at epoch 5 step 2500 = 1.4941 (time=1.2270)\n",
      "Loss at epoch 5 step 2600 = 1.7741 (time=1.2559)\n",
      "Loss at epoch 5 step 2700 = 1.5860 (time=1.2553)\n",
      "Loss at epoch 5 step 2800 = 1.8140 (time=1.2825)\n",
      "Loss at epoch 5 step 2900 = 1.6133 (time=1.2323)\n",
      "Total mean loss = 1.59973267364\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder(inputSize=INDEXER.nWords, hiddenSize=20)\n",
    "dec = Decoder(inputSize=INDEXER.nWords, hiddenSize=20)\n",
    "encOptim = optim.Adam(enc.parameters(), 1e-4)\n",
    "decOptim = optim.Adam(dec.parameters(), 1e-4)\n",
    "criterion = nn.NLLLoss()\n",
    "meanLoss, enc, dec = train(pairs,lengths,enc,dec,encOptim,decOptim,criterion)\n",
    "print('Total mean loss =', meanLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D. EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, sentence, correctTranslation, indexer):\n",
    "    with torch.no_grad():\n",
    "        source = to_tensor(sentence)\n",
    "        length = len(sentence)\n",
    "        encoderOutputs = torch.zeros(MAX_LENGTH, encoder.hiddenSize, device=device) # for attention later\n",
    "        encoderHidden = encoder.init_hidden()\n",
    "        for ei in range(length):\n",
    "            encoderOutput,encoderHidden = encoder(source[ei],encoderHidden)\n",
    "            encoderOutputs[ei] = encoderOutput[0][0] # <mt=bc=1,h>\n",
    "        decoderInput = torch.tensor([[0]], device=device)\n",
    "        decoderHidden = encoderHidden  \n",
    "        translatedSentence = []\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoderOutput,decoderHidden = decoder(decoderInput,decoderHidden)\n",
    "            topValue,topIndex = decoderOutput.topk(1)\n",
    "#             decoderInput = topIndex.squeeze().detach()\n",
    "            decoderInput = topIndex\n",
    "            translatedSentence.append(decoderInput.item())\n",
    "            if decoderInput.item() == 1 or decoderInput.item() == 4: # 1:EOS; 4:.\n",
    "                break # hitting end of sentence\n",
    "        translatedSentence = indexer.get_sentence_word(translatedSentence)\n",
    "    print('Original sentence >', ' '.join(indexer.get_sentence_word(sentence)))\n",
    "    print('Model translation >', ' '.join(translatedSentence))\n",
    "    print('Correct translation >', ' '.join(indexer.get_sentence_word(correctTranslation)),'\\n')\n",
    "    \n",
    "def random_translate(encoder, decoder, indexer, k=10):\n",
    "    for _ in range(k):\n",
    "        i = random.randint(0,len(pairs))\n",
    "        translate(encoder, decoder, pairs[i][0], pairs[i][1], indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence > SOS G C B EOS\n",
      "Model translation > SOS B D C\n",
      "Correct translation > SOS H D C EOS \n",
      "\n",
      "Original sentence > SOS H F C H EOS\n",
      "Model translation > SOS I D I I EOS EOS EOS EOS EOS\n",
      "Correct translation > SOS I G D I EOS \n",
      "\n",
      "Original sentence > SOS F B G E C C D EOS\n",
      "Model translation > SOS H E D D D F F D EOS\n",
      "Correct translation > SOS G C H F D D E EOS \n",
      "\n",
      "Original sentence > SOS C F A A C D C EOS\n",
      "Model translation > SOS D D D D B B B EOS EOS\n",
      "Correct translation > SOS D G B B D E D EOS \n",
      "\n",
      "Original sentence > SOS C D G H D D G EOS\n",
      "Model translation > SOS D F E I E G\n",
      "Correct translation > SOS D E H I E E H EOS \n",
      "\n",
      "Original sentence > SOS G G E B D F B EOS\n",
      "Model translation > SOS B B B E E E E EOS EOS\n",
      "Correct translation > SOS H H F C E G C EOS \n",
      "\n",
      "Original sentence > SOS B G F EOS\n",
      "Model translation > SOS C\n",
      "Correct translation > SOS C H G EOS \n",
      "\n",
      "Original sentence > SOS B D D EOS\n",
      "Model translation > SOS E E E EOS EOS EOS EOS EOS EOS\n",
      "Correct translation > SOS C E E EOS \n",
      "\n",
      "Original sentence > SOS G B D B A EOS\n",
      "Model translation > SOS B C\n",
      "Correct translation > SOS H C E C B EOS \n",
      "\n",
      "Original sentence > SOS H G B C C C EOS\n",
      "Model translation > SOS I I D D D D EOS EOS EOS\n",
      "Correct translation > SOS I H C D D D EOS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_translate(enc, dec, INDEXER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
